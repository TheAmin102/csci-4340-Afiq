{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the data from the CSV file\n",
    "data = pd.read_csv('puf2022_MinMaxScaler.csv')\n",
    "\n",
    "# Split the data into predictors (X) and target (y)\n",
    "X = data.drop(columns=['PRICE'])\n",
    "y = data['PRICE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 1067674889.9380\n",
      "Root Mean Squared Error (RMSE): 32675.2948\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "# Separate features and target variable\n",
    "X = data.drop(\"PRICE\", axis=1)  # Features\n",
    "y = data[\"PRICE\"]  # Target variable\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Create a random forest regressor\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model on the training data\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "# Evaluate the model's performance using mean squared error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)  # Root mean squared error\n",
    "print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Mean Squared Error of the model is: 1067735825.2138768\n",
      "Mean Squared Error (MSE): 1067735825.2139\n",
      "Root Mean Squared Error (RMSE): 32676.2272\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Assuming X is your feature matrix and y is your target variable\n",
    "# Modify this part based on your actual dataset\n",
    "\n",
    "# Separate features and target variable\n",
    "X = data.drop(\"PRICE\", axis=1)  # Features\n",
    "y = data[\"PRICE\"]  # Target variable\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Create a new XGBoost regressor (for regression task)\n",
    "xgb_reg = xgb.XGBRegressor(objective ='reg:squarederror', n_estimators=100, random_state=42)\n",
    "\n",
    "# Fit the model to the training data\n",
    "xgb_reg.fit(X_train, y_train)\n",
    "\n",
    "# Predict the target variable for the testing data\n",
    "y_pred = xgb_reg.predict(X_test)\n",
    "\n",
    "# Calculate the Mean Squared Error (MSE) as a metric\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f'The Mean Squared Error of the model is: {mse}')\n",
    "\n",
    "# Evaluate the model's performance using mean squared error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)  # Root mean squared error\n",
    "\n",
    "# Display the results\n",
    "print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000385 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 194\n",
      "[LightGBM] [Info] Number of data points in the train set: 3171, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 127964.406496\n",
      "Mean Squared Error (MSE): 878902204.6703\n",
      "Root Mean Squared Error (RMSE): 29646.2848\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Assuming X is your feature matrix and y is your target variable\n",
    "# Modify this part based on your actual dataset\n",
    "\n",
    "# Separate features and target variable\n",
    "X = data.drop(\"PRICE\", axis=1)  # Features\n",
    "y = data[\"PRICE\"]  # Target variable\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Create a new LightGBM regressor (for regression task)\n",
    "lgb_reg = lgb.LGBMRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Fit the model to the training data\n",
    "lgb_reg.fit(X_train, y_train)\n",
    "\n",
    "# Predict the target variable for the testing data\n",
    "y_pred = lgb_reg.predict(X_test)\n",
    "\n",
    "# Evaluate the model's performance using mean squared error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)  # Root mean squared error\n",
    "\n",
    "# Display the results\n",
    "print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The R-squared score of the model is: 0.6539\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import Lasso\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "\n",
    "# Split the data into predictors (X) and target (y)\n",
    "X = data.drop(columns=['PRICE'])\n",
    "y = data['PRICE']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Create a new Lasso regressor\n",
    "lasso = Lasso(alpha=0.1)\n",
    "\n",
    "# Create a new XGBoost regressor\n",
    "xgb = XGBRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Create a new voting regressor with 65% Lasso and 35% XGBoost\n",
    "hybrid = VotingRegressor(estimators=[('lasso', lasso), ('xgb', xgb)], weights=[0.65, 0.35])\n",
    "\n",
    "# Fit the model to the training data\n",
    "hybrid.fit(X_train, y_train)\n",
    "\n",
    "# Predict the target variable for the testing data\n",
    "y_pred = hybrid.predict(X_test)\n",
    "\n",
    "# Print the R-squared score of the model\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f'The R-squared score of the model is: {r2:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The R-squared score of the model is: 0.6733\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import Lasso\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "# Split the data into predictors (X) and target (y)\n",
    "X = data.drop(columns=['PRICE'])\n",
    "y = data['PRICE']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Create a new Lasso regressor\n",
    "lasso = Lasso(alpha=0.1)\n",
    "\n",
    "# Create a new XGBoost regressor\n",
    "xgb = XGBRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Create a new stacking regressor with Lasso and XGBoost as base estimators\n",
    "stacked = StackingRegressor(\n",
    "    estimators=[('lasso', lasso), ('xgb', xgb)],\n",
    "    final_estimator=XGBRegressor(n_estimators=50, random_state=42)\n",
    ")\n",
    "\n",
    "# Fit the model to the training data\n",
    "stacked.fit(X_train, y_train)\n",
    "\n",
    "# Predict the target variable for the testing data\n",
    "y_pred = stacked.predict(X_test)\n",
    "\n",
    "# Print the R-squared score of the model\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f'The R-squared score of the model is: {r2:.4f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

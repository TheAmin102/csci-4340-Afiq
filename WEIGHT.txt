notes:
data analysis x masukan 
visualization training data
RMSLE train set test set
comparison predicted result and original test set 
applied log transformation for any skewed data 
abnormal point 
refocus algorithm
list of no features/ score/ alpha RMSE / 
comparison hybrid method and original algorithm and original test set

Standardization
Normalization

Robust Techniques: Consider using models that are inherently robust to outliers, such as decision trees, random forests, or quantile regression.
Winsorizing: Instead of outright removal, outliers can be capped at specific percentiles (e.g., 95th and 5th percentiles) to mitigate their influence without discarding them entirely.
Incorporating Outliers: If outliers are informative, try incorporating them into the modeling process through techniques like weighted modeling or outlier-specific features.

Random Forest
Extreme Gradient Boosting (XGBoost)
Light Gradient Boosting Machine (LightGBM)
Hybrid Regression 65% Lasso and 35% XGBoost
Stacked Generalization
Ridge
lasso = it said that it great at features selection using alpha parameter
gradient Boosting
lasso + gradient boosting hybrid 
0.7 lasso + 0.3 XGBoost
0.65Ridge+0.35Xgb 
 0.70Lasso+0.30Xgb 
 0.65Lasso+0.35Xgb 
 0.60Lasso+0.40Xgb 
 0.3Ridge+0.35Lasso+0.35Xgb 
 0.25Ridge+0.40Lasso+0.35Xgb 
 0.65Ridge+0.35Xgb 
 0.65Lasso+0.35Xgb


available column in this csv 
Index(['WEIGHT', 'STATUS', 'FINALDEST', 'FOOTINGS', 'LEASE', 'LOCATION',
       'REGION', 'PIERS', 'SECURED', 'TITLED', 'SECTIONS', 'PRICE', 'SQFT',
       'BEDROOMS', 'SHIPMONTH', 'WGTADJ', 'CONTROL', 'jstatus', 'jprice',
       'jsqft', 'jbedroom', 'jlease', 'jfinaldest', 'jtitle', 'jsecured',
       'jlocation', 'jfootings', 'jpiers'],
      dtype='object')
      
RMSE (Root Mean Squared Error)
MAE (Mean Absolute Error)
MAPE (Mean Absolute Percentage Error)
RMSLE problem because negative value 

try to visuliza and bind with SQFT and BEDROOMS
Scatter Plot with Regression Line
Residual Plot
prediction vs training data
price vs prediction